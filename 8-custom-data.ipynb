{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Custom Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll see how to use torchtext to work with custom data.  Many of the steps, like specifying field objects to process and numericalize the data are the same.  One difference is that we now use the `TabularDataset` method to read csv, and json files.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can begin by loading our data from the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "coconut_water_df = pd.read_csv('./coconut_water.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = coconut_water_df.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our data is often read locally using torchtext, let's create a folder called `data` and then save the data to the path `/data/coconut_reviews.csv`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.to_csv('./data/coconut_reviews.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's check that we stored it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "coconut_water_df = pd.read_csv('./data/coconut_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1314144000</td>\n",
       "      <td>Switched to O.N.E.</td>\n",
       "      <td>Must admit the taste of O.N.E. coconut water i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1313884800</td>\n",
       "      <td>WOW!!</td>\n",
       "      <td>I love this stuff!  Perfect blend of dark choc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score        Time             Summary  \\\n",
       "0      1  1314144000  Switched to O.N.E.   \n",
       "1      5  1313884800               WOW!!   \n",
       "\n",
       "                                                Text  \n",
       "0  Must admit the taste of O.N.E. coconut water i...  \n",
       "1  I love this stuff!  Perfect blend of dark choc...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coconut_water_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now, let's try to use our data in `/data/coconut_reviews.csv` with torchtext.  We can do so by first defining a list of fields, and then specifying where we will read the files with `data.TabularDataset.splits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "import torch\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "SCORE = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('score', SCORE), (None, None), (None, None), ('text', TEXT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'data',\n",
    "                                        train = 'coconut_reviews.csv',\n",
    "    test = 'coconut_reviews.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we have a list of examples that we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[0].score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to break down the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we used `data.Field` to define fields for each column from our dataset that we wanted to process.  So we defined a TEXT field for both the TEXT, and for the SCORE, our target.  Then we specified a list tuples, one tuple for each element in our csv file.  If we do not want to include the column, we fill our tuple with the elements `(None, None)`.  If we do want to include the column, then we specify the name of the attribute we want to store for the column, as well as the predefined field to process the text with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this if we take a closer look at one of our `examples` from our `train_data` above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x12a69d550>,\n",
       " <torchtext.data.example.Example at 0x126bae750>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_example = train_data.examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our example, has score and text attributes, just as we defined above in our `fields` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_example.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Must', 'admit', 'the', 'taste', 'of']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_example.text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have initialized our dataset, we can then numericalize and batch our data just as we've done previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "SCORE.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 1852),\n",
       " ('I', 1470),\n",
       " ('the', 1457),\n",
       " (',', 1191),\n",
       " ('and', 962),\n",
       " ('it', 857),\n",
       " ('a', 828),\n",
       " ('to', 762),\n",
       " (' ', 705),\n",
       " ('is', 628)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we look at how our labels are translated to numbers, we do not currently translate them to the corresponding integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'5': 0, '1': 1, '4': 2, '3': 3, '2': 4})"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORE.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set up the translation that we prefer by setting `stoi` to our own dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE.vocab.stoi = {'5': 5, '1': 1, '4': 4, '3': 3, '2': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can batch the data with the bucket iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "train_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "    sort_key=lambda x: len(x.text),\n",
    "    batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that above we are specifying a `sort_key`.  The bucketiterator needs to be told how to bucket the data, and here we specify to batch the data by the length of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's select the first batch from the from our `train_iter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    first_batch = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the data, it seems like it was numericalized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 62,   3,  32,  ..., 145,   3,   3],\n",
       "        [ 11,  64,  88,  ...,   8, 293, 717],\n",
       "        [  8,  60,  26,  ..., 721,  16, 101],\n",
       "        ...,\n",
       "        [  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  1,   1,   1,  ...,   1,   1,   1]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_doc_in_batch = first_batch.text[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'product',\n",
       " '.',\n",
       " ' ',\n",
       " 'Although',\n",
       " 'I',\n",
       " \"'d\",\n",
       " 'initially',\n",
       " 'planned',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'a']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[TEXT.vocab.itos[i] for i in first_doc_in_batch][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the scores in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 2., 1., 5., 5., 5., 5., 1., 3., 5., 1., 3., 1., 1., 4., 5., 1.,\n",
       "        5., 5., 5., 4., 4., 5., 1., 5., 1., 5., 5., 5., 4., 5., 5., 5., 5., 5.,\n",
       "        4., 2., 3., 4., 5., 5., 5., 4., 5., 1., 5., 5., 5., 4., 1., 5., 5., 5.,\n",
       "        4., 1., 5., 5., 1., 5., 1., 5., 5., 5., 5., 5., 5., 3., 5., 5., 5., 5.,\n",
       "        5., 5., 1., 3., 4., 1., 5., 4., 1., 5., 5., 3., 5., 5., 5., 1., 1., 1.,\n",
       "        3., 1., 1., 5., 5., 5., 5., 5., 5., 1.])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with json occurs in a similar manner.  One difference is how we specify the fields.  Notice that with json, we specify the name of the key in the dictionary, and then follow suit with the tuple.  When we do not wish to include a key with the json, we can simply leave out the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields = {'score': ('score', SCORE), 'text': ('text', TEXT)}\n",
    "# train_data, test_data = data.TabularDataset.splits(\n",
    "#                             path = 'data',\n",
    "#                             train = 'train.json',\n",
    "#                             test = 'test.json',\n",
    "#                             format = 'json',\n",
    "#                             fields = fields\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we saw how to work with a custom dataset with torchtext.  We begin by initializing and specifying each field that we would like to use.  Our field object specifies how to tokenize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from torchtext import data\n",
    "import torch\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "SCORE = data.LabelField(dtype = torch.float)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we declare a list of tuples where we specify the name of the attribute we would like our field to be stored as, and the Field object used to process it.\n",
    "\n",
    "```python\n",
    "fields = [('score', SCORE), (None, None), (None, None), ('text', TEXT)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with json, this collections of fields is a dictionary.\n",
    "\n",
    "```python\n",
    "fields = {'score': ('score', SCORE), 'text': ('text', TEXT)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we retreive the data with the `TabularDataset` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'data',\n",
    "                                        train = 'coconut_reviews.csv',\n",
    "    test = 'coconut_reviews.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then numericalize with `build_vocab`, and batch the data with the BucketIterator as we have previously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
